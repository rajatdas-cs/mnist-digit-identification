{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mjjumJxthH3w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "data = pd.read_csv('mnist_test.csv')\n",
        "data = np.array(data)"
      ],
      "metadata": {
        "id": "lwA_PhxWhUDf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-process the data\n",
        "X = data[:, 1:] / 255  # Normalize pixel values to be between 0 and 1\n",
        "y = data[:, 0]         # Labels (digit values)\n",
        "\n",
        "# Shuffle the data\n",
        "indices = np.random.permutation(len(X))\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Split the data into training and test sets\n",
        "split_idx = int(0.8 * len(X))  # Use 80% for training, 20% for testing\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]"
      ],
      "metadata": {
        "id": "v9toYURBh_n-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(784, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "L_VpR_pHsdKj"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lUL27Z-ZtRQa"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyKfM5WutWKd",
        "outputId": "b4e8e3f7-a1fe-4696-fe20-b7779fb59963"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 3s 22ms/step - loss: 2.2360 - accuracy: 0.2254 - val_loss: 2.0819 - val_accuracy: 0.3060\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.9925 - accuracy: 0.3955 - val_loss: 1.8807 - val_accuracy: 0.4940\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.7907 - accuracy: 0.5599 - val_loss: 1.6907 - val_accuracy: 0.6525\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.6069 - accuracy: 0.7080 - val_loss: 1.5109 - val_accuracy: 0.7715\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 1.4288 - accuracy: 0.7900 - val_loss: 1.3460 - val_accuracy: 0.8185\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 1.2625 - accuracy: 0.8374 - val_loss: 1.1877 - val_accuracy: 0.8530\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.1105 - accuracy: 0.8727 - val_loss: 1.0606 - val_accuracy: 0.8575\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.9751 - accuracy: 0.8939 - val_loss: 0.9301 - val_accuracy: 0.8925\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.8565 - accuracy: 0.9096 - val_loss: 0.8283 - val_accuracy: 0.8985\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.7547 - accuracy: 0.9199 - val_loss: 0.7367 - val_accuracy: 0.9115\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.6654 - accuracy: 0.9309 - val_loss: 0.6590 - val_accuracy: 0.9170\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.5874 - accuracy: 0.9398 - val_loss: 0.5974 - val_accuracy: 0.9215\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5188 - accuracy: 0.9457 - val_loss: 0.5376 - val_accuracy: 0.9205\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.4548 - accuracy: 0.9549 - val_loss: 0.4883 - val_accuracy: 0.9280\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.4005 - accuracy: 0.9596 - val_loss: 0.4503 - val_accuracy: 0.9260\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.3535 - accuracy: 0.9645 - val_loss: 0.4068 - val_accuracy: 0.9340\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.3113 - accuracy: 0.9701 - val_loss: 0.3780 - val_accuracy: 0.9370\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.2747 - accuracy: 0.9740 - val_loss: 0.3480 - val_accuracy: 0.9375\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.2425 - accuracy: 0.9770 - val_loss: 0.3256 - val_accuracy: 0.9395\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.2140 - accuracy: 0.9809 - val_loss: 0.3124 - val_accuracy: 0.9350\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.1905 - accuracy: 0.9836 - val_loss: 0.2975 - val_accuracy: 0.9395\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.1681 - accuracy: 0.9843 - val_loss: 0.2819 - val_accuracy: 0.9430\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1488 - accuracy: 0.9875 - val_loss: 0.2683 - val_accuracy: 0.9415\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1315 - accuracy: 0.9896 - val_loss: 0.2600 - val_accuracy: 0.9425\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1178 - accuracy: 0.9906 - val_loss: 0.2507 - val_accuracy: 0.9435\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1053 - accuracy: 0.9921 - val_loss: 0.2462 - val_accuracy: 0.9435\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0941 - accuracy: 0.9935 - val_loss: 0.2369 - val_accuracy: 0.9440\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0850 - accuracy: 0.9949 - val_loss: 0.2335 - val_accuracy: 0.9460\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0766 - accuracy: 0.9951 - val_loss: 0.2305 - val_accuracy: 0.9445\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0685 - accuracy: 0.9969 - val_loss: 0.2231 - val_accuracy: 0.9490\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0624 - accuracy: 0.9973 - val_loss: 0.2201 - val_accuracy: 0.9480\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0567 - accuracy: 0.9977 - val_loss: 0.2197 - val_accuracy: 0.9475\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0517 - accuracy: 0.9979 - val_loss: 0.2202 - val_accuracy: 0.9470\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0472 - accuracy: 0.9981 - val_loss: 0.2174 - val_accuracy: 0.9500\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0436 - accuracy: 0.9983 - val_loss: 0.2160 - val_accuracy: 0.9495\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0402 - accuracy: 0.9985 - val_loss: 0.2141 - val_accuracy: 0.9480\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0371 - accuracy: 0.9985 - val_loss: 0.2135 - val_accuracy: 0.9505\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0343 - accuracy: 0.9985 - val_loss: 0.2138 - val_accuracy: 0.9520\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0317 - accuracy: 0.9991 - val_loss: 0.2123 - val_accuracy: 0.9495\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0291 - accuracy: 0.9992 - val_loss: 0.2140 - val_accuracy: 0.9490\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0270 - accuracy: 0.9994 - val_loss: 0.2153 - val_accuracy: 0.9505\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0250 - accuracy: 0.9995 - val_loss: 0.2112 - val_accuracy: 0.9500\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0229 - accuracy: 0.9995 - val_loss: 0.2162 - val_accuracy: 0.9505\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0212 - accuracy: 0.9999 - val_loss: 0.2139 - val_accuracy: 0.9480\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9480\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9480\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9485\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9485\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9485\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9495\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9500\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9505\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9495\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9520\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9505\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9495\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9505\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9510\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9510\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9515\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9510\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9520\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9515\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9520\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9515\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9520\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9525\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9525\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9520\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9520\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9520\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9525\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9525\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9525\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9520\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9520\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9540\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9520\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9530\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9525\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9535\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9525\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9535\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9530\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9535\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9530\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9540\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9530\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9535\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9530\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9520\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9535\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9540\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9530\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9545\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9550\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9535\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9545\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9535\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9530\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ea07e4461d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N78lhr0txP8",
        "outputId": "8c5c3b37-c128-44b5-84db-916fa4fa8550"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9530\n",
            "Test accuracy: 0.9530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test[6].reshape(1, -1))\n",
        "predicted_digit = np.argmax(prediction)\n",
        "print(f'Predicted digit: {predicted_digit}')\n",
        "\n",
        "image = X_test[6]\n",
        "image = image.reshape((28, 28)) * 255\n",
        "plt.gray()\n",
        "plt.imshow(image, interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "cNnpgWAWx_it",
        "outputId": "9e059ed5-a6ec-416d-f613-56aa50037b82"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "Predicted digit: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict digit from user-uploaded image\n",
        "def predict_digit(image_path):\n",
        "    # Open the image and reshape it to a 1D array\n",
        "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "    img = img.resize((28, 28))  # Resize to 28x28\n",
        "    img_array = np.array(img).flatten() / 255  # Normalize pixel values\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array.reshape(1, -1))\n",
        "    predicted_digit = np.argmax(prediction)\n",
        "\n",
        "    return predicted_digit\n",
        "\n",
        "# Example usage\n",
        "image_path = 'path/to/your/image.png'  # Replace with the actual path to your image\n",
        "predicted_digit = predict_digit(image_path)\n",
        "print(f'The predicted digit is: {predicted_digit}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "2GvqFx3yxOm8",
        "outputId": "ac896d36-6111-4056-c320-92511e29ba2a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/your/image.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-58c4e57e2318>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/your/image.png'\u001b[0m  \u001b[0;31m# Replace with the actual path to your image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredicted_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The predicted digit is: {predicted_digit}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-58c4e57e2318>\u001b[0m in \u001b[0;36mpredict_digit\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Open the image and reshape it to a 1D array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Resize to 28x28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m  \u001b[0;31m# Normalize pixel values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/image.png'"
          ]
        }
      ]
    }
  ]
}